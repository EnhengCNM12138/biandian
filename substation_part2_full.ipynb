{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3bf358",
   "metadata": {},
   "source": [
    "\n",
    "# 变电站故障检测\n",
    "- Baseline + 创新点1 \n",
    "- 端到端：数据加载--训练--推理--评估  \n",
    "- **11 个正确标签**：\n",
    "`'bj_bpmh', 'bj_bpps', 'bj_wkps', 'bjdsye', 'jyz_pl', 'sly_dmyw', 'hxg_gjbs', 'hxq_gjtps', 'xmbhyc', 'yw_gkxfw', 'yw_nc'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda | Classes: 11\n"
     ]
    }
   ],
   "source": [
    "import os, math, time, json, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torchvision import transforms, models\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if CUDA else 'cpu')\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if CUDA: torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "SAFE_MAX_PIXELS = 384 * 384   \n",
    "USE_FP16 = True              \n",
    "TIMESTEPS_SAFE = [200]        \n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'bj_bpmh', 'bj_bpps', 'bj_wkps', 'bjdsyc', 'jyz_pl', 'sly_dmyw',\n",
    "    'hxq_gjbs', 'hxq_gjtps', 'xmbhyc', 'yw_gkxfw', 'yw_nc'\n",
    "]\n",
    "print('Device:', DEVICE, '| Classes:', len(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caff8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#功能：将 4D 图像张量（B,C,H,W）安全缩放到不超过 SAFE_MAX_PIXELS 的像素上限，避免显存暴涨。\n",
    "\n",
    "def safe_resize_bchw(x: torch.Tensor) -> torch.Tensor:\n",
    "    B,C,H,W = x.shape\n",
    "    if H*W <= SAFE_MAX_PIXELS:\n",
    "        return x\n",
    "    scale = (SAFE_MAX_PIXELS / float(H*W)) ** 0.5\n",
    "    newH, newW = max(64, int(H*scale)), max(64, int(W*scale))\n",
    "    return F.interpolate(x, size=(newH,newW), mode='bilinear', align_corners=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f1e76b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 已启用更强数据增强与标准化\n"
     ]
    }
   ],
   "source": [
    "#功能：解析单个 VOC 风格 XML，提取类别名\n",
    "\n",
    "def parse_xml(xml_path: str) -> Optional[str]:\n",
    "    try:\n",
    "        root = ET.parse(xml_path).getroot()\n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text.strip()\n",
    "            return name\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "#功能：自定义数据集类，从指定目录加载图像-标签对\n",
    "class SubstationDataset(Dataset):\n",
    "    def __init__(self, images_dir: str, annos_dir: str, transform=None,\n",
    "                 class_names: List[str] = None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.annos_dir = Path(annos_dir)\n",
    "        self.transform = transform\n",
    "        self.class_names = class_names or list(CLASS_NAMES)\n",
    "        self.class_to_idx = {c:i for i,c in enumerate(self.class_names)}\n",
    "        self.data_pairs = []\n",
    "        exts = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}\n",
    "        annos = [p for p in self.annos_dir.iterdir() if p.suffix.lower()=='.xml']\n",
    "        for ap in annos:\n",
    "            label = parse_xml(str(ap))\n",
    "            if label is None: \n",
    "                continue\n",
    "            if label not in self.class_to_idx:\n",
    "                continue\n",
    "            img_stem = ap.stem\n",
    "            img_candidate = None\n",
    "            for ext in exts:\n",
    "                ip = self.images_dir / f\"{img_stem}{ext}\"\n",
    "                if ip.exists():\n",
    "                    img_candidate = ip; break\n",
    "            if img_candidate is None:\n",
    "                for p in self.images_dir.iterdir():\n",
    "                    if p.suffix.lower() in exts and p.stem == img_stem:\n",
    "                        img_candidate = p; break\n",
    "            if img_candidate is not None:\n",
    "                self.data_pairs.append( (str(img_candidate), self.class_to_idx[label]) )\n",
    "        if len(self.data_pairs)==0:\n",
    "            print(\"[WARN] No matched image-xml pairs found.\")\n",
    "\n",
    "    def __len__(self): return len(self.data_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ip, y = self.data_pairs[idx]\n",
    "        img = Image.open(ip).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "#功能：返回训练/验证两套 torchvision.transforms 变换\n",
    "#训练：随机水平/垂直翻转、颜色抖动、缩放、ToTensor\n",
    "#验证：缩放、ToTensor\n",
    "'''def get_transforms(img_size=256):\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    return train_tf, val_tf'''\n",
    "\n",
    "    # === 更强数据增强（减轻过拟合）===\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "def get_transforms(img_size=256):\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.3,0.3,0.3,0.15)], p=0.8),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(3, sigma=(0.1, 1.5))], p=0.3),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize(int(img_size*1.14), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "    return train_tf, val_tf\n",
    "\n",
    "print('[Info] 已启用更强数据增强与标准化')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db652034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1902f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#新增：无LabelSmoothing + Mixup + TTA\n",
    "\n",
    "# === 掩膜视图：在已有 train_tf 基础上叠加随机块遮挡 + RandomErasing ===\n",
    "class MaskedViewTransform:\n",
    "    def __init__(self, base_tfm, use_block_mask=True, use_random_erasing=True, max_blocks=2, erasing_p=0.25):\n",
    "        self.base_tfm = base_tfm\n",
    "        self.use_block_mask = use_block_mask\n",
    "        self.use_random_erasing = use_random_erasing\n",
    "        self.max_blocks = max_blocks\n",
    "        from torchvision import transforms\n",
    "        self.random_erasing = transforms.RandomErasing(p=erasing_p, value=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _block_mask(img_tensor, max_blocks=2):\n",
    "        # img_tensor: Tensor [C, H, W]\n",
    "        import random\n",
    "        c, h, w = img_tensor.shape\n",
    "        blocks = random.randint(1, max_blocks)\n",
    "        for _ in range(blocks):\n",
    "            rh = int(h * random.uniform(0.2, 0.35))\n",
    "            rw = int(w * random.uniform(0.2, 0.35))\n",
    "            y0 = random.randint(0, max(0, h - rh))\n",
    "            x0 = random.randint(0, max(0, w - rw))\n",
    "            img_tensor[:, y0:y0+rh, x0:x0+rw] = 0.0\n",
    "        return img_tensor\n",
    "\n",
    "    def __call__(self, pil_img):\n",
    "        x = self.base_tfm(pil_img)\n",
    "        if self.use_block_mask:\n",
    "            x = self._block_mask(x, self.max_blocks)\n",
    "        if self.use_random_erasing:\n",
    "            x = self.random_erasing(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SubstationDatasetFromPairsMV(Dataset):\n",
    "    \"\"\"训练：返回双视图 (view1, view2, label)\"\"\"\n",
    "    def __init__(self, pairs, tfm_view1, tfm_view2):\n",
    "        self.pairs = pairs\n",
    "        self.tfm1 = tfm_view1\n",
    "        self.tfm2 = tfm_view2\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ip, y = self.pairs[i]\n",
    "        from PIL import Image\n",
    "        img = Image.open(ip).convert('RGB')\n",
    "        x1 = self.tfm1(img)\n",
    "        x2 = self.tfm2(img)\n",
    "        return x1, x2, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22235694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5dd927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#功能：扩散过程类，包含 q_sample 和 p_sample 方法\n",
    "#定义离散扩散过程的时间表与前向/反向采样公式（DDPM 公式族）\n",
    "class DiffusionProcess(nn.Module):\n",
    "    def __init__(self, num_timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        super().__init__()\n",
    "        betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1,0), value=1.0)\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "# 功能：前向采样，生成带噪声的图像(前向加噪)\n",
    "# 输入：原始图像 x_start, 时间步 t, 可选噪声 noise\n",
    "# 输出：带噪声的图像 x_noisy\n",
    "# 实现：根据时间步 t 的 alpha 和 beta 计算加噪强度，生成带噪声的图像\n",
    "# 关键点：用 sqrt(ᾱ_t)、sqrt(1-ᾱ_t) 线性混合 x_start 与 noise\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        acp = self.alphas_cumprod.to(t.device)\n",
    "        sqrt_acp = torch.sqrt(acp.gather(0, t)).view(-1,1,1,1)\n",
    "        sqrt_om = torch.sqrt((1.0 - acp).gather(0, t)).view(-1,1,1,1)\n",
    "        return sqrt_acp * x_start + sqrt_om * noise\n",
    "\n",
    "# 功能：反向采样，从带噪声的图像恢复原始图像(反向去噪,调用 U-Net 预测噪声,支持类条件传递)\n",
    "# 输入：U-Net 模型, 带噪声的图像 x, 时间步 t, 时间步索引 t_index, 可选类条件标签 class_labels\n",
    "# 输出：恢复的原始图像\n",
    "# 实现：根据时间步 t 的 alpha 和 beta 计算去噪强度，结合 U-Net 预测的噪声，恢复原始图像\n",
    "# 关键点：用 sqrt(ᾱ_t)、sqrt(1-ᾱ_t) 线性混合 x 与 U-Net 预测的噪声(类条件会被透传到去噪器)\n",
    "    def p_sample(self, model, x, t, t_index, class_labels=None):\n",
    "        betas_t = self.betas.to(t.device).gather(0, t).view(-1,1,1,1)\n",
    "        acp_t = self.alphas_cumprod.to(t.device).gather(0, t)\n",
    "        alphas_t = self.alphas.to(t.device).gather(0, t)\n",
    "        sqrt_one_minus = torch.sqrt(1.0 - acp_t).view(-1,1,1,1)\n",
    "        sqrt_recip = torch.sqrt(1.0 / alphas_t).view(-1,1,1,1)\n",
    "        pred_noise = model(x, t, class_labels=class_labels)\n",
    "        model_mean = sqrt_recip * (x - betas_t * pred_noise / sqrt_one_minus)\n",
    "        if t_index == 0:\n",
    "            return model_mean\n",
    "        post_var_t = self.posterior_variance.to(t.device).gather(0, t).view(-1,1,1,1)\n",
    "        return model_mean + torch.sqrt(post_var_t) * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#功能：U-Net 的残差块，包含时间条件、类条件传递、短连接等.\n",
    "#输入：输入特征 x, 时间嵌入 t_emb, 可选类条件 cond\n",
    "#输出：输出特征 h,(与 out_ch 匹配的特征图)\n",
    "#实现：\n",
    "# 1) 两个 3x3 卷积 + 时间条件 + 类条件传递\n",
    "# 2) 短连接：如果输入输出通道数相同，则直接相加；否则用 1x1 卷积调整通道数\n",
    "# 3) 使用 SiLU 激活函数，可选 Dropout 正则化\n",
    "class ResidBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, cond_dim=None, p=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_fc = nn.Linear(time_dim, out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.short = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.use_film = cond_dim is not None\n",
    "        if self.use_film:\n",
    "            self.gamma = nn.Linear(cond_dim, out_ch)\n",
    "            self.beta  = nn.Linear(cond_dim, out_ch)\n",
    "\n",
    "    def forward(self, x, t_emb, cond=None):\n",
    "        h = self.conv1(x)\n",
    "        h = h + self.time_fc(t_emb)[:, :, None, None]\n",
    "        if self.use_film:\n",
    "            gamma = self.gamma(cond)[:, :, None, None]\n",
    "            beta  = self.beta(cond)[:, :, None, None]\n",
    "            h = h * (1 + gamma) + beta\n",
    "        h = self.act(h)\n",
    "        h = self.drop(h)\n",
    "        h = self.conv2(h)\n",
    "        return h + self.short(x)\n",
    "\n",
    "#功能：增强 U-Net 模型,扩散去噪器（U-Net），支持时间条件、类条件传递、短连接等.\n",
    "#输入：输入特征 x, 时间步 timestep, 可选类条件 class_labels\n",
    "#输出：预测的噪声(与输入图像同尺寸的 3 通道张量)\n",
    "#实现：\n",
    "# 1) 时间条件：将时间步转换为嵌入，与特征图拼接\n",
    "# 2) 类条件：如果提供，则转换为可学习的提示，与特征图拼接\n",
    "# 3) 残差块：包含两个 3x3 卷积 + 时间条件 + 类条件传递 + 短连接\n",
    "# 4) 短连接：如果输入输出通道数相同，则直接相加；否则用 1x1 卷积调整通道数\n",
    "# 5) 使用 SiLU 激活函数，可选 Dropout 正则化\n",
    "# 6) 使用 avg_pool2d 下采样，使用 F.interpolate 上采样\n",
    "# 7) 使用 torch.cat 拼接特征图，实现跳跃连接\n",
    "# 8) 使用 nn.Conv2d 输出预测的噪声\n",
    "class EnhancedUNet(nn.Module):\n",
    "    def __init__(self, num_classes: int, base_ch=64, use_film=True, use_attention=False, width_mult=1.0):\n",
    "        super().__init__()\n",
    "        ch = int(base_ch * width_mult)\n",
    "        self.use_film = use_film\n",
    "        self.use_attention = use_attention\n",
    "        time_dim = ch * 4\n",
    "        cond_dim = ch * 2 if use_film else None\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, ch), nn.SiLU(),\n",
    "            nn.Linear(ch, time_dim)\n",
    "        )\n",
    "        self.learnable_prompts = nn.Embedding(num_classes, cond_dim if use_film else 1)\n",
    "\n",
    "        # encoder\n",
    "        self.enc1 = ResidBlock(3,      ch,   time_dim, cond_dim)\n",
    "        self.enc2 = ResidBlock(ch,     ch*2, time_dim, cond_dim)\n",
    "        self.enc3 = ResidBlock(ch*2,   ch*4, time_dim, cond_dim)\n",
    "        self.mid  = ResidBlock(ch*4,   ch*4, time_dim, cond_dim)\n",
    "\n",
    "        # decoder (concat skips)\n",
    "        self.dec3 = ResidBlock(ch*4 + ch*2, ch*2, time_dim, cond_dim)  \n",
    "        self.dec2 = ResidBlock(ch*2 + ch,   ch,   time_dim, cond_dim)  \n",
    "        self.dec1 = nn.Conv2d(ch, 3, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, timestep, class_labels=None):\n",
    "        if class_labels is None:\n",
    "            class_labels = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        t = timestep.view(-1, 1).float()\n",
    "        t_emb = self.time_mlp(t)\n",
    "        cond = self.learnable_prompts(class_labels) if self.use_film else None\n",
    "\n",
    "        # encoder\n",
    "        e1 = self.enc1(x,               t_emb, cond)        \n",
    "        e2 = self.enc2(F.avg_pool2d(e1, 2), t_emb, cond)   \n",
    "        e3 = self.enc3(F.avg_pool2d(e2, 2), t_emb, cond)    \n",
    "        m  = self.mid(e3,               t_emb, cond)      \n",
    "\n",
    "        # decoder with concat skips\n",
    "        up_m = F.interpolate(m, scale_factor=2, mode='nearest')  \n",
    "        #d3_in = torch.cat([up_m, e2], dim=1)                    \n",
    "        d3 = self.dec3(torch.cat([up_m, e2], dim=1), t_emb, cond) \n",
    "\n",
    "        up_d3 = F.interpolate(d3, scale_factor=2, mode='nearest')     \n",
    "        #d2_in = torch.cat([up_d3, e1], dim=1)                    \n",
    "        d2 = self.dec2(torch.cat([up_d3, e1], dim=1), t_emb, cond)\n",
    "\n",
    "        out = self.dec1(d2)                       \n",
    "        return out\n",
    "  # predicted noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e8315a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#残差提取与多尺度\n",
    "#功能：多尺度残差提取器，支持多尺度残差提取与扩散去噪.利用扩散反推把输入图像“还原”到接近正常，再与原图取绝对差，得到残差；可按多时间步提取。\n",
    "#输入：扩散去噪器, 时间步列表\n",
    "#输出：多尺度残差列表\n",
    "#实现：\n",
    "# 1) 初始化：保存扩散去噪器与时间步列表\n",
    "# 2) 前向：对每个时间步，调用扩散去噪器进行反向采样，得到残差\n",
    "# 3) 返回：所有时间步的残差列表\n",
    "# 4) 使用 torch.no_grad() 装饰器，避免梯度计算\n",
    "class MultiScaleResidualExtractor(nn.Module):\n",
    "    def __init__(self, diffusion_model: EnhancedUNet, timesteps: List[int]):\n",
    "        super().__init__()\n",
    "        self.diffusion_model = diffusion_model\n",
    "        self.timesteps = timesteps\n",
    "        self.diffusion_process = DiffusionProcess()\n",
    "\n",
    "#功能：提取单个时间步的残差,从给定时间步 t_value 反推到 0，得到还原图 x̂ 并计算 |x - x̂|\n",
    "#输入：输入图像 x, 标签 labels, 时间步 t_value, 步数 steps\n",
    "#输出：残差\n",
    "#关键点：每步都携带 class_labels（innov1 的类条件反推）\n",
    "#实现：\n",
    "# 1) 初始化：保存扩散去噪器与时间步列表\n",
    "# 2) 前向：对每个时间步，调用扩散去噪器进行反向采样，得到残差\n",
    "# 3) 返回：所有时间步的残差列表\n",
    "# 被谁调用：验证/推理，多尺度时会被多次调用后堆叠。\n",
    "    @torch.no_grad()\n",
    "    def extract_one_timestep(self, x, labels, t_value: int, steps: int = 8):\n",
    "        dev = next(self.parameters()).device\n",
    "        x = x.to(dev, non_blocking=True)\n",
    "        x_t = torch.randn_like(x)\n",
    "        stride = max(1, int(t_value // max(1, steps)))\n",
    "        for i in range(t_value, -1, -stride):\n",
    "            tt = torch.full((x.size(0),), i, device=dev, dtype=torch.long)\n",
    "            x_t = self.diffusion_process.p_sample(self.diffusion_model, x_t, tt, i, class_labels=labels.to(dev))\n",
    "        residual = (x - x_t).abs()\n",
    "        return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d7d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 已覆盖 ResidualClassifier：加入 Dropout 与 LabelSmoothing 支持（由 Trainer 使用）\n"
     ]
    }
   ],
   "source": [
    "#分类器与多尺度融合\n",
    "#功能：残差分类器，将多尺度残差堆叠后，用 ResNet50 提取特征，最后用全连接层分类.对单张残差图做分类。\n",
    "#输入：多尺度残差列表\n",
    "#输出：分类结果\n",
    "#关键点：ResNet50(IMAGENET1K_V2) 作为骨干，只替换最后全连接层输出通道数\n",
    "#实现：\n",
    "# 1) 初始化：加载 ResNet50 模型，替换最后一层全连接为 num_classes 输出\n",
    "# 2) 前向：对每个多尺度残差，用 ResNet50 提取特征，最后用全连接层分类\n",
    "# 3) 返回：分类结果\n",
    "# 被谁调用：验证/推理，多尺度时会被多次调用后堆叠。\n",
    "'''class ResidualClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_feat = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_feat, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)'''\n",
    "\n",
    "# === 覆盖 ResidualClassifier：更强正则（Dropout/LabelSmoothing 支持）===\n",
    "class ResidualClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int, p_drop=0.4, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        in_feat = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.Linear(in_feat, num_classes)\n",
    "        )\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "print('[Info] 已覆盖 ResidualClassifier：加入 Dropout 与 LabelSmoothing 支持（由 Trainer 使用）')\n",
    "\n",
    "\n",
    "\n",
    "#功能：多尺度融合分类器，将多尺度残差堆叠后，用 2 层 3x3 卷积 + 平均池化 + 全连接层分类.\n",
    "#输入：残差栈 (B,T,C,H,W)\n",
    "#关键点：先把 (T,C,H,W) 当“伪通道”或展平做轻量卷积/池化，再接全连接层。\n",
    "#被谁调用：Innov2（多时间步） \n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int, num_timesteps: int = 1, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((8,8))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*8*8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): # [B,T,C,H,W]\n",
    "        if x.dim()==4:\n",
    "            x = x.unsqueeze(1)\n",
    "        B,T,C,H,W = x.shape\n",
    "        x = x.mean(dim=1)  # avg over time\n",
    "        h = self.conv(x)\n",
    "        h = self.pool(h).view(B,-1)\n",
    "        return self.fc(h)\n",
    "\n",
    "# 功能：Transformer 融合分类器，将多尺度残差堆叠后（把残差栈先做网格池化到固定维度，投影为序列），用 Transformer 提取特征，最后用全连接层分类.\n",
    "#把 (B,T,C,H,W) 先做网格池化到固定维度，投影为序列，再用 TransformerEncoder 做时序/尺度建模。\n",
    "#残差栈 (B,T,C,H,W) → 网格池化 → 序列 (B,T,C*g*g) → TransformerEncoder → 平均池化 (B,D) → 全连接 (B,num_classes)\n",
    "#关键点：每一帧残差提取一个 token，Transformer 编码，做时序平均池化再分类。\n",
    "#被谁调用：Innov2（多时间步 + Transformer 融合）\n",
    "class TransformerFusionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=11, num_timesteps=1, in_channels=3, grid=8,\n",
    "                 proj_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.grid = grid\n",
    "        self.proj = nn.Linear(in_channels * grid * grid, proj_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=proj_dim, nhead=8, dim_feedforward=1024, dropout=0.1, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(proj_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):  # [B,T,C,H,W]\n",
    "        if x.dim()==4:\n",
    "            x = x.unsqueeze(1)\n",
    "        B,T,C,H,W = x.shape\n",
    "        feats = []\n",
    "        for i in range(T):\n",
    "            f = F.adaptive_avg_pool2d(x[:,i], (self.grid, self.grid))  \n",
    "            f = f.view(B, -1)                                         \n",
    "            f = self.proj(f)                                     \n",
    "            feats.append(f)\n",
    "        seq = torch.stack(feats, dim=1)                       \n",
    "        enc = self.encoder(seq).mean(dim=1) \n",
    "        return self.fc(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc691cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 端到端模型封装\n",
    "# 功能：封装了创新1/2的模型，包括扩散去噪器、多尺度残差提取器、残差分类器、Transformer 融合分类器。\n",
    "# 基线总成：DiffusionProcess + EnhancedUNet(use_film=False) + ResidualClassifier\n",
    "# 输入：图像 x, 标签 labels, 模式 mode\n",
    "# 输出：预测的噪声, 噪声, 时间步, 标签\n",
    "# 关键点：训练时残差支路不回传梯度（通过 no_grad 或单独函数），扩散器只用 MSE 学“正常先验”，分类器用 CE 学“看残差分类”\n",
    "\n",
    "\n",
    "class BaselineFaultDetector(nn.Module):\n",
    "    def __init__(self, num_classes=11, img_size=256):\n",
    "        super().__init__()\n",
    "        self.diffusion = DiffusionProcess()\n",
    "        self.unet = EnhancedUNet(num_classes=num_classes, use_film=False, width_mult=0.75)\n",
    "        self.classifier = ResidualClassifier(num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None, mode='train'):\n",
    "        if mode == 'train':\n",
    "            b = x.shape[0]\n",
    "            t = torch.randint(0, self.diffusion.num_timesteps, (b,), device=x.device).long()\n",
    "            noise = torch.randn_like(x)\n",
    "            x_noisy = self.diffusion.q_sample(x, t, noise)\n",
    "            pred_noise = self.unet(x_noisy, t, class_labels=None)\n",
    "            return pred_noise, noise, t, None\n",
    "        else:\n",
    "            with torch.inference_mode():\n",
    "                res = MultiScaleResidualExtractor(self.unet, TIMESTEPS_SAFE).extract_one_timestep(\n",
    "                    x, labels if labels is not None else torch.zeros(x.size(0), dtype=torch.long, device=x.device),\n",
    "                    t_value=200, steps=8\n",
    "                )\n",
    "                logits = self.classifier(res)\n",
    "                return res.unsqueeze(1), logits\n",
    "\n",
    "# 创新1总成：DiffusionProcess + EnhancedUNet(use_film=True) + ResidualClassifier\n",
    "# U-Net 开启 use_film=True，并在反推/训练都传入 class_labels\n",
    "# 关键点：FiLM 条件：nn.Embedding(num_classes, cond_dim) 生成类条件向量，注入各残差块；\n",
    "# 反推时也传 labels 给 p_sample，确保“按该类正常形态”还原；\n",
    "# 保持损失组合 MSE + 0.5×CE 与解耦训练不变。\n",
    "\n",
    "class Innovation1FaultDetector(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.diffusion_process = DiffusionProcess()\n",
    "        self.diffusion_model = EnhancedUNet(num_classes=num_classes, use_film=True, width_mult=0.75)\n",
    "        self.classifier = ResidualClassifier(num_classes)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reconstruct_residual_fast(self, x, labels, t_start=200, steps=10):\n",
    "        dev = next(self.parameters()).device\n",
    "        x = x.to(dev)\n",
    "        x_t = torch.randn_like(x)\n",
    "        stride = max(1, int(t_start // max(1, steps)))\n",
    "        for i in range(t_start, -1, -stride):\n",
    "            tt = torch.full((x.size(0),), i, device=dev, dtype=torch.long)\n",
    "            x_t = self.diffusion_process.p_sample(self.diffusion_model, x_t, tt, i, class_labels=labels.to(dev))\n",
    "        return (x - x_t).abs()\n",
    "\n",
    "    def forward(self, x, labels=None, mode='train'):\n",
    "        if labels is None:\n",
    "            labels = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        if mode == 'train':\n",
    "            b = x.shape[0]\n",
    "            t = torch.randint(0, self.diffusion_process.num_timesteps, (b,), device=x.device).long()\n",
    "            noise = torch.randn_like(x)\n",
    "            x_noisy = self.diffusion_process.q_sample(x, t, noise)\n",
    "            pred_noise = self.diffusion_model(x_noisy, t, class_labels=labels)\n",
    "            return pred_noise, noise, t, None\n",
    "        else:\n",
    "            with torch.inference_mode():\n",
    "                res = self.reconstruct_residual_fast(x, labels, t_start=200, steps=8)\n",
    "                logits = self.classifier(res)\n",
    "                return res.unsqueeze(1), logits\n",
    "\n",
    "# 创新2总成：DiffusionProcess + EnhancedUNet(use_film=True) + MultiScaleResidualExtractor + FusionClassifier/TransformerFusionClassifier\n",
    "class Innovation2FaultDetector(nn.Module):\n",
    "    def __init__(self, num_classes=11, use_transformer=True, timesteps=[200], lightweight=True):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.timesteps = timesteps\n",
    "        self.lightweight = lightweight\n",
    "\n",
    "        self.diffusion_process = DiffusionProcess()\n",
    "        self.diffusion_model = EnhancedUNet(num_classes=num_classes, use_film=True,\n",
    "                                            use_attention=(False if lightweight else True),\n",
    "                                            width_mult=(0.75 if lightweight else 1.0))\n",
    "        self.residual_extractor = MultiScaleResidualExtractor(self.diffusion_model, self.timesteps)\n",
    "        if lightweight or not use_transformer:\n",
    "            self.fusion_classifier = FusionClassifier(num_classes=num_classes, num_timesteps=len(self.timesteps))\n",
    "        else:\n",
    "            self.fusion_classifier = TransformerFusionClassifier(num_classes=num_classes, num_timesteps=len(self.timesteps))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reconstruct_residual_fast(self, x, labels, t_start=200, steps=8):\n",
    "        dev = next(self.parameters()).device\n",
    "        x = x.to(dev)\n",
    "        x_t = torch.randn_like(x)\n",
    "        stride = max(1, int(t_start // max(1, steps)))\n",
    "        for i in range(t_start, -1, -stride):\n",
    "            tt = torch.full((x.size(0),), i, device=dev, dtype=torch.long)\n",
    "            x_t = self.diffusion_process.p_sample(self.diffusion_model, x_t, tt, i, class_labels=labels.to(dev))\n",
    "        return (x - x_t).abs()\n",
    "\n",
    "    def forward(self, x, labels=None, mode='train'):\n",
    "        if labels is None:\n",
    "            labels = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        if mode == 'train':\n",
    "            b = x.shape[0]\n",
    "            t = torch.randint(0, self.diffusion_process.num_timesteps, (b,), device=x.device).long()\n",
    "            noise = torch.randn_like(x)\n",
    "            masked_x = x\n",
    "            x_noisy = self.diffusion_process.q_sample(masked_x, t, noise)\n",
    "            pred_noise = self.diffusion_model(x_noisy, t, class_labels=labels)\n",
    "            return pred_noise, noise, t, None\n",
    "        else:\n",
    "            self.eval()\n",
    "            dev = next(self.parameters()).device\n",
    "            timesteps = self.timesteps if (self.lightweight is False) else TIMESTEPS_SAFE\n",
    "            with torch.inference_mode():\n",
    "                residual_list = []\n",
    "                for t in timesteps:\n",
    "                    res_t = self.reconstruct_residual_fast(x, labels, t_start=int(t), steps=8)  # [B,C,H,W]\n",
    "                    residual_list.append(res_t)\n",
    "                res_stack = torch.stack(residual_list, dim=1)  # [B,T,C,H,W]\n",
    "                logits = self.fusion_classifier(res_stack.to(next(self.fusion_classifier.parameters()).device))\n",
    "                return res_stack, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "AMP_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# 训练器\n",
    "# 功能：训练模型，包括前向、损失计算、反向传播、梯度裁剪、优化器更新等；封装优化器、损失、AMP、单轮训练与验证逻辑、保存最优模型。\n",
    "# 关键点：使用 GradScaler 处理混合精度训练，使用交叉熵损失计算分类误差，使用 MSE 损失计算扩散损失。\n",
    "# 优化器：AdamW；混合精度：GradScaler；\n",
    "# 损失：mse = MSE(pred_noise, noise)；ce = CE(logits, y)；总损失 loss = mse + 0.5*ce；\n",
    "# 保存：当 val_acc 创新高就 torch.save\n",
    "'''class Trainer:\n",
    "    def __init__(self, model: nn.Module, lr=2e-4, weight_decay=5e-4):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        #self.scaler = torch.cuda.amp.GradScaler(enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.scaler = GradScaler(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "\n",
    "#对每个 batch：采样 t 加噪 → U-Net 预测噪声 → MSE；无梯度重构残差 → 分类器 → CE；loss = MSE + 0.5×CE 反传更新；统计训练准确率。\n",
    "# 可选：用 train_eval_loader 在自然分布上再测一次 train_acc。\n",
    "    def train_epoch(self, loader):\n",
    "        self.model.train()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            self.optim.zero_grad(set_to_none=True)\n",
    "            #with torch.cuda.amp.autocast(enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "            with autocast(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "                out = self.model(imgs, labels=ys, mode='train')\n",
    "                if isinstance(out, tuple):\n",
    "                    pred_noise, noise, t, _ = out\n",
    "                    diffusion_loss = self.mse(pred_noise, noise)\n",
    "                else:\n",
    "                    diffusion_loss = torch.tensor(0., device=DEVICE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if hasattr(self.model, 'reconstruct_residual_fast'):\n",
    "                        res = self.model.reconstruct_residual_fast(imgs, ys, t_start=200, steps=8)\n",
    "                    else:\n",
    "                        res = MultiScaleResidualExtractor(self.model.unet, TIMESTEPS_SAFE).extract_one_timestep(imgs, ys, t_value=200, steps=8)\n",
    "                if hasattr(self.model, 'fusion_classifier'):\n",
    "                    logits = self.model.fusion_classifier(res.unsqueeze(1).to(next(self.model.fusion_classifier.parameters()).device))\n",
    "                else:\n",
    "                    logits = self.model.classifier(res)\n",
    "                ce = self.ce(logits, ys)\n",
    "                loss = diffusion_loss + 0.5 * ce\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(self.optim)\n",
    "            self.scaler.update()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == ys).sum().item()\n",
    "                total += ys.size(0)\n",
    "                loss_sum += loss.item() * ys.size(0)\n",
    "\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "# 验证器:验证评估。走推理路径（反推→残差→分类），统计 val_loss/val_ac\n",
    "# 关键点：不做反传；与训练的残差支路保持一致的生成逻辑；遇到更高 acc 即保存 best\n",
    "    @torch.no_grad()\n",
    "    def validate(self, loader):\n",
    "        self.model.eval()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            res_stack, logits = self.model(imgs, labels=ys, mode='eval')\n",
    "            ce = self.ce(logits, ys)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred==ys).sum().item()\n",
    "            total += ys.size(0)\n",
    "            loss_sum += ce.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb1fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights_ce: [0.504 0.577 0.835 0.613 0.999 0.565 0.399 4.314 1.15  0.576 0.468]\n",
      "train/val sizes: 5216 1304\n",
      "class counts (train): [616 538 372 507 311 550 778  72 270 539 663]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMAGES_DIR = '/mnt/e/code/project/Dataset-total/images' \n",
    "ANNOTATIONS_DIR = '/mnt/e/code/project/Dataset-total/annotations/xmls' \n",
    "img_size = 256\n",
    "val_ratio = 0.2\n",
    "bs = 8\n",
    "workers = 4\n",
    "\n",
    "'''train_tf, val_tf = get_transforms(img_size)\n",
    "base = SubstationDataset(IMAGES_DIR, ANNOTATIONS_DIR, transform=None, class_names=list(CLASS_NAMES))\n",
    "indices = np.arange(len(base))\n",
    "if len(indices)==0:\n",
    "    raise RuntimeError('No data found. Please check paths.')\n",
    "labels_np = np.array([ base.data_pairs[i][1] for i in indices ])\n",
    "\n",
    "train_idx, val_idx = train_test_split(indices, test_size=val_ratio, random_state=SEED, stratify=labels_np)\n",
    "\n",
    "train_ds = SubstationDataset(IMAGES_DIR, ANNOTATIONS_DIR, transform=train_tf, class_names=list(CLASS_NAMES))\n",
    "val_ds   = SubstationDataset(IMAGES_DIR, ANNOTATIONS_DIR, transform=val_tf,   class_names=list(CLASS_NAMES))\n",
    "train_ds = Subset(train_ds, train_idx.tolist())\n",
    "val_ds   = Subset(val_ds,   val_idx.tolist())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=max(1,bs//2), shuffle=False, num_workers=workers, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds)'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) 只构建一次数据集，拿到稳定的 pairs\n",
    "_base = SubstationDataset(IMAGES_DIR, ANNOTATIONS_DIR, transform=None, class_names=list(CLASS_NAMES))\n",
    "pairs = _base.data_pairs  # [(img_path, class_idx), ...]\n",
    "\n",
    "if len(pairs) == 0:\n",
    "    raise RuntimeError('No data found. Check IMAGES_DIR / ANNOTATIONS_DIR.')\n",
    "\n",
    "# 2) 按同一份 pairs 做可复现的划分\n",
    "indices = np.arange(len(pairs))\n",
    "labels_np = np.array([ y for _, y in pairs ])\n",
    "train_idx, val_idx = train_test_split(indices, test_size=val_ratio, random_state=SEED, stratify=labels_np)\n",
    "\n",
    "# 3) 用“同一清单 + 不同 transform”构建 Dataset 封装器，避免重新枚举文件\n",
    "'''class SubstationDatasetFromPairs(Dataset):\n",
    "    def __init__(self, pairs, transform=None):\n",
    "        self.pairs = pairs\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ip, y = self.pairs[i]\n",
    "        img = Image.open(ip).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "train_tf, val_tf = get_transforms(img_size)\n",
    "train_ds = SubstationDatasetFromPairs([pairs[i] for i in train_idx], transform=train_tf)\n",
    "val_ds   = SubstationDatasetFromPairs([pairs[i] for i in val_idx],   transform=val_tf)'''\n",
    "\n",
    "# 新增：无LabelSmoothing + Mixup + TTA\n",
    "# 3) 用“同一清单 + 不同 transform”构建 Dataset 封装器（训练=双视图，验证=单视图）\n",
    "class SubstationDatasetFromPairs(Dataset):\n",
    "    def __init__(self, pairs, transform=None):\n",
    "        self.pairs = pairs\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ip, y = self.pairs[i]\n",
    "        from PIL import Image\n",
    "        img = Image.open(ip).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, y\n",
    "\n",
    "train_tf, val_tf = get_transforms(img_size)\n",
    "\n",
    "# === 新增：掩膜视图（在 train_tf 基础上叠加遮挡/擦除）===\n",
    "masked_train_tf = MaskedViewTransform(\n",
    "    base_tfm=train_tf,\n",
    "    use_block_mask=True,\n",
    "    use_random_erasing=True,\n",
    "    max_blocks=2,\n",
    "    erasing_p=0.25\n",
    ")\n",
    "\n",
    "# 训练集换成双视图（view1=原训练增强；view2=掩膜训练增强）\n",
    "train_ds = SubstationDatasetFromPairsMV([pairs[i] for i in train_idx], tfm_view1=train_tf, tfm_view2=masked_train_tf)\n",
    "# 验证集保持单视图\n",
    "val_ds   = SubstationDatasetFromPairs([pairs[i] for i in val_idx],   transform=val_tf)\n",
    "\n",
    "\n",
    "# 4) loader：训练用加权采样，评估用自然分布\n",
    "use_weighted_sampler = True\n",
    "\n",
    "if use_weighted_sampler:\n",
    "    train_labels = [ y for _, y in [pairs[i] for i in train_idx] ]\n",
    "    counts = np.bincount(train_labels, minlength=len(CLASS_NAMES))\n",
    "    #class_weights = 1.0 / np.clip(counts, a_min=1, a_max=None)\n",
    "    inv = 1.0 / np.clip(counts, a_min=1, a_max=None)\n",
    "    class_weights_ce = (inv / inv.sum()) * len(inv)          # 归一到均值≈1\n",
    "    CLASS_WEIGHTS_TENSOR = torch.tensor(class_weights_ce, dtype=torch.float32, device=DEVICE)\n",
    "    print('class_weights_ce:', np.round(class_weights_ce, 3))\n",
    "    \n",
    "    sample_weights = [ class_weights_ce[y] for y in train_labels ]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    train_loader = DataLoader(train_ds, batch_size=bs, sampler=sampler, num_workers=workers, pin_memory=True)\n",
    "else:\n",
    "    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# 验证集始终用自然分布 + 顺序采样\n",
    "val_loader = DataLoader(val_ds,   batch_size=max(1,bs//2), shuffle=False, num_workers=workers, pin_memory=True)\n",
    "# 另外做一个“训练集评估 loader”（自然分布），用于客观的 train_acc\n",
    "train_eval_loader = DataLoader(train_ds, batch_size=max(1,bs//2), shuffle=False, num_workers=workers, pin_memory=True)\n",
    "\n",
    "print('train/val sizes:', len(train_ds), len(val_ds))\n",
    "if use_weighted_sampler: print('class counts (train):', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7597cba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 已创建分离的数据加载器：\n",
      "  - Baseline: train=5216 (单视图), val=1304\n",
      "  - Innovation1: train=5216 (双视图), val=1304\n"
     ]
    }
   ],
   "source": [
    "# ==================== 分离数据加载器：Baseline vs Innovation1 ====================\n",
    "# Baseline专用数据加载器：单视图，无掩膜\n",
    "train_ds_baseline = SubstationDatasetFromPairs([pairs[i] for i in train_idx], transform=train_tf)\n",
    "val_ds_baseline = val_ds  # 验证集通用\n",
    "\n",
    "if use_weighted_sampler:\n",
    "    sampler_baseline = torch.utils.data.WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    train_loader_baseline = DataLoader(train_ds_baseline, batch_size=bs, sampler=sampler_baseline, num_workers=workers, pin_memory=True)\n",
    "else:\n",
    "    train_loader_baseline = DataLoader(train_ds_baseline, batch_size=bs, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "# Innovation1专用数据加载器：双视图（含掩膜）\n",
    "train_ds_innov1 = train_ds  # 使用前面定义的双视图数据集\n",
    "val_ds_innov1 = val_ds      # 验证集通用\n",
    "\n",
    "train_loader_innov1 = train_loader  # 使用前面定义的加权采样loader\n",
    "\n",
    "val_loader_baseline = val_loader   # 验证集通用\n",
    "val_loader_innov1 = val_loader     # 验证集通用\n",
    "\n",
    "print('[Info] 已创建分离的数据加载器：')\n",
    "print(f'  - Baseline: train={len(train_ds_baseline)} (单视图), val={len(val_ds_baseline)}')\n",
    "print(f'  - Innovation1: train={len(train_ds_innov1)} (双视图), val={len(val_ds_innov1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43f68fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from torch.amp import autocast, GradScaler\\n\\ndef _label_smoothing_ce(logits, targets, smoothing=0.1):\\n    if smoothing <= 0:\\n        return F.cross_entropy(logits, targets)\\n    n_class = logits.size(1)\\n    log_prob = F.log_softmax(logits, dim=1)\\n    with torch.no_grad():\\n        true_dist = torch.zeros_like(log_prob)\\n        true_dist.fill_(smoothing / (n_class - 1))\\n        true_dist.scatter_(1, targets.unsqueeze(1), 1 - smoothing)\\n    return torch.mean(torch.sum(-true_dist * log_prob, dim=1))\\n\\nAMP_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\\ndef _label_smoothing_ce(logits, targets, smoothing=0.1, weight=None):\\n    n = logits.size(1)\\n    logp = F.log_softmax(logits, dim=1)\\n    with torch.no_grad():\\n        true_dist = torch.zeros_like(logp)\\n        true_dist.fill_(smoothing / (n - 1))\\n        true_dist.scatter_(1, targets.unsqueeze(1), 1 - smoothing)\\n    loss = torch.sum(-true_dist * logp, dim=1)       # [B]\\n    if weight is not None:\\n        loss = loss * weight[targets]                # 类加权\\n    return loss.mean()\\n\\nclass Trainer:\\n    def __init__(self, model: nn.Module, lr=2e-4, weight_decay=5e-4, mixup_alpha=0.2, tta_times=4):\\n        self.model = model.to(DEVICE)\\n        self.optim = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\\n        #self.scaler = GradScaler(DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\\n        self.scaler = GradScaler(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\\n        self.mse = nn.MSELoss()\\n        self.mixup_alpha = mixup_alpha\\n        self.tta_times = tta_times\\n\\n    def _mixup(self, x, y, alpha):\\n        if alpha <= 0:\\n            return x, y, 1.0\\n        lam = np.random.beta(alpha, alpha)\\n        idx = torch.randperm(x.size(0), device=x.device)\\n        x_mix = lam * x + (1 - lam) * x[idx]\\n        return x_mix, (y, y[idx]), lam\\n\\n    def _tta_predict(self, imgs, labels):\\n        # 简单 TTA：水平翻转 + 旋转 90/270\\n        logits_sum = 0\\n        imgs_tta = [imgs,\\n                    torch.flip(imgs, dims=[-1]),\\n                    imgs.transpose(-1, -2),\\n                    torch.flip(imgs.transpose(-1, -2), dims=[-1])]\\n        with torch.no_grad():\\n            for im in imgs_tta[:self.tta_times]:\\n                out = self.model(im, labels=labels, mode='eval')\\n                if isinstance(out, tuple) and len(out)==2:\\n                    _, logits = out\\n                else:\\n                    # Baseline/Innov1 eval 都返回 (res_stack/logits)\\n                    _, logits = out\\n                logits_sum = logits_sum + logits\\n        return logits_sum / len(imgs_tta[:self.tta_times])\\n\\n    def train_epoch(self, loader):\\n        self.model.train()\\n        total, correct, loss_sum = 0, 0, 0.0\\n        for imgs, ys in loader:\\n            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\\n            self.optim.zero_grad(set_to_none=True)\\n            # Mixup\\n            imgs_mix, ys_tuple, lam = self._mixup(imgs, ys, self.mixup_alpha)\\n            #with autocast(DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\\n            with autocast(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\\n                out = self.model(imgs_mix, labels=ys, mode='train')\\n                if isinstance(out, tuple):\\n                    pred_noise, noise, t, _ = out\\n                    diffusion_loss = self.mse(pred_noise, noise)\\n                else:\\n                    diffusion_loss = torch.tensor(0., device=DEVICE)\\n\\n                with torch.no_grad():\\n                    if hasattr(self.model, 'reconstruct_residual_fast'):\\n                        res = self.model.reconstruct_residual_fast(imgs_mix, ys, t_start=200, steps=6)\\n                    else:\\n                        res = MultiScaleResidualExtractor(self.model.unet, TIMESTEPS_SAFE).extract_one_timestep(imgs_mix, ys, t_value=200, steps=6)\\n                if hasattr(self.model, 'fusion_classifier'):\\n                    logits = self.model.fusion_classifier(res.unsqueeze(1).to(next(self.model.fusion_classifier.parameters()).device))\\n                else:\\n                    logits = self.model.classifier(res)\\n\\n                if isinstance(ys_tuple, tuple):\\n                    y1, y2 = ys_tuple\\n                    ce = lam * _label_smoothing_ce(logits, y1, smoothing=0.1) + (1-lam) * _label_smoothing_ce(logits, y2, smoothing=0.1)\\n\\n                    # 若有 mixup:\\n                    ce = lam * _label_smoothing_ce(logits, y1, 0.1, CLASS_WEIGHTS_TENSOR)+ (1-lam) * _label_smoothing_ce(logits, y2, 0.1, CLASS_WEIGHTS_TENSOR)\\n                else:\\n                    #ce = _label_smoothing_ce(logits, ys, smoothing=0.1)\\n                    ce = _label_smoothing_ce(logits, ys, smoothing=0.1, weight=CLASS_WEIGHTS_TENSOR)\\n                loss = diffusion_loss + 0.5 * ce\\n\\n            self.scaler.scale(loss).backward()\\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\\n            self.scaler.step(self.optim)\\n            self.scaler.update()\\n\\n            with torch.no_grad():\\n                pred = logits.argmax(1)\\n                correct += (pred == ys).sum().item()\\n                total += ys.size(0)\\n                loss_sum += loss.item() * ys.size(0)\\n        return loss_sum/total, correct/total\\n\\n    @torch.no_grad()\\n    def validate(self, loader):\\n        self.model.eval()\\n        total, correct, loss_sum = 0, 0, 0.0\\n        for imgs, ys in loader:\\n            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\\n            logits = self._tta_predict(imgs, ys)\\n            #ce = F.cross_entropy(logits, ys)\\n            ce = F.cross_entropy(logits, ys, weight=CLASS_WEIGHTS_TENSOR)\\n            pred = logits.argmax(1)\\n            correct += (pred==ys).sum().item()\\n            total += ys.size(0)\\n            loss_sum += ce.item() * ys.size(0)\\n        return loss_sum/total, correct/total\\n\\nprint('[Info] Trainer 已增强：LabelSmoothing + Mixup + TTA')\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 舍弃：仅label smoothing+mixup+tta\n",
    "# === 覆盖 Trainer：Label Smoothing + Mixup + TTA ===\n",
    "'''from torch.amp import autocast, GradScaler\n",
    "\n",
    "def _label_smoothing_ce(logits, targets, smoothing=0.1):\n",
    "    if smoothing <= 0:\n",
    "        return F.cross_entropy(logits, targets)\n",
    "    n_class = logits.size(1)\n",
    "    log_prob = F.log_softmax(logits, dim=1)\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.zeros_like(log_prob)\n",
    "        true_dist.fill_(smoothing / (n_class - 1))\n",
    "        true_dist.scatter_(1, targets.unsqueeze(1), 1 - smoothing)\n",
    "    return torch.mean(torch.sum(-true_dist * log_prob, dim=1))\n",
    "\n",
    "AMP_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def _label_smoothing_ce(logits, targets, smoothing=0.1, weight=None):\n",
    "    n = logits.size(1)\n",
    "    logp = F.log_softmax(logits, dim=1)\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.zeros_like(logp)\n",
    "        true_dist.fill_(smoothing / (n - 1))\n",
    "        true_dist.scatter_(1, targets.unsqueeze(1), 1 - smoothing)\n",
    "    loss = torch.sum(-true_dist * logp, dim=1)       # [B]\n",
    "    if weight is not None:\n",
    "        loss = loss * weight[targets]                # 类加权\n",
    "    return loss.mean()\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module, lr=2e-4, weight_decay=5e-4, mixup_alpha=0.2, tta_times=4):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        #self.scaler = GradScaler(DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.scaler = GradScaler(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.tta_times = tta_times\n",
    "\n",
    "    def _mixup(self, x, y, alpha):\n",
    "        if alpha <= 0:\n",
    "            return x, y, 1.0\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        idx = torch.randperm(x.size(0), device=x.device)\n",
    "        x_mix = lam * x + (1 - lam) * x[idx]\n",
    "        return x_mix, (y, y[idx]), lam\n",
    "\n",
    "    def _tta_predict(self, imgs, labels):\n",
    "        # 简单 TTA：水平翻转 + 旋转 90/270\n",
    "        logits_sum = 0\n",
    "        imgs_tta = [imgs,\n",
    "                    torch.flip(imgs, dims=[-1]),\n",
    "                    imgs.transpose(-1, -2),\n",
    "                    torch.flip(imgs.transpose(-1, -2), dims=[-1])]\n",
    "        with torch.no_grad():\n",
    "            for im in imgs_tta[:self.tta_times]:\n",
    "                out = self.model(im, labels=labels, mode='eval')\n",
    "                if isinstance(out, tuple) and len(out)==2:\n",
    "                    _, logits = out\n",
    "                else:\n",
    "                    # Baseline/Innov1 eval 都返回 (res_stack/logits)\n",
    "                    _, logits = out\n",
    "                logits_sum = logits_sum + logits\n",
    "        return logits_sum / len(imgs_tta[:self.tta_times])\n",
    "\n",
    "    def train_epoch(self, loader):\n",
    "        self.model.train()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            self.optim.zero_grad(set_to_none=True)\n",
    "            # Mixup\n",
    "            imgs_mix, ys_tuple, lam = self._mixup(imgs, ys, self.mixup_alpha)\n",
    "            #with autocast(DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "            with autocast(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "                out = self.model(imgs_mix, labels=ys, mode='train')\n",
    "                if isinstance(out, tuple):\n",
    "                    pred_noise, noise, t, _ = out\n",
    "                    diffusion_loss = self.mse(pred_noise, noise)\n",
    "                else:\n",
    "                    diffusion_loss = torch.tensor(0., device=DEVICE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if hasattr(self.model, 'reconstruct_residual_fast'):\n",
    "                        res = self.model.reconstruct_residual_fast(imgs_mix, ys, t_start=200, steps=6)\n",
    "                    else:\n",
    "                        res = MultiScaleResidualExtractor(self.model.unet, TIMESTEPS_SAFE).extract_one_timestep(imgs_mix, ys, t_value=200, steps=6)\n",
    "                if hasattr(self.model, 'fusion_classifier'):\n",
    "                    logits = self.model.fusion_classifier(res.unsqueeze(1).to(next(self.model.fusion_classifier.parameters()).device))\n",
    "                else:\n",
    "                    logits = self.model.classifier(res)\n",
    "\n",
    "                if isinstance(ys_tuple, tuple):\n",
    "                    y1, y2 = ys_tuple\n",
    "                    ce = lam * _label_smoothing_ce(logits, y1, smoothing=0.1) + (1-lam) * _label_smoothing_ce(logits, y2, smoothing=0.1)\n",
    "\n",
    "                    # 若有 mixup:\n",
    "                    ce = lam * _label_smoothing_ce(logits, y1, 0.1, CLASS_WEIGHTS_TENSOR)+ (1-lam) * _label_smoothing_ce(logits, y2, 0.1, CLASS_WEIGHTS_TENSOR)\n",
    "                else:\n",
    "                    #ce = _label_smoothing_ce(logits, ys, smoothing=0.1)\n",
    "                    ce = _label_smoothing_ce(logits, ys, smoothing=0.1, weight=CLASS_WEIGHTS_TENSOR)\n",
    "                loss = diffusion_loss + 0.5 * ce\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(self.optim)\n",
    "            self.scaler.update()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == ys).sum().item()\n",
    "                total += ys.size(0)\n",
    "                loss_sum += loss.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, loader):\n",
    "        self.model.eval()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            logits = self._tta_predict(imgs, ys)\n",
    "            #ce = F.cross_entropy(logits, ys)\n",
    "            ce = F.cross_entropy(logits, ys, weight=CLASS_WEIGHTS_TENSOR)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred==ys).sum().item()\n",
    "            total += ys.size(0)\n",
    "            loss_sum += ce.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "print('[Info] Trainer 已增强：LabelSmoothing + Mixup + TTA')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a1ddd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 已创建双Trainer系统：BaselineTrainer（无约束） + Innovation1Trainer（FiLM+掩膜+三重约束）\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 双Trainer系统：Baseline专用 + Innovation1专用\n",
    "# ===============================================\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "AMP_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ==================== Baseline专用Trainer ====================\n",
    "# 功能：仅支持 MSE(扩散) + CE(分类)，无掩膜、无三重约束\n",
    "# 适用于：BaselineFaultDetector\n",
    "class BaselineTrainer:\n",
    "    \"\"\"Baseline专用训练器：扩散MSE + 残差分类CE，无额外约束\"\"\"\n",
    "    def __init__(self, model: nn.Module, lr=2e-4, weight_decay=5e-4):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scaler = GradScaler(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def train_epoch(self, loader):\n",
    "        \"\"\"训练：单视图，MSE + CE\"\"\"\n",
    "        self.model.train()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            self.optim.zero_grad(set_to_none=True)\n",
    "            with autocast(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "                # 扩散MSE\n",
    "                out = self.model(imgs, labels=ys, mode='train')\n",
    "                if isinstance(out, tuple):\n",
    "                    pred_noise, noise, t, _ = out\n",
    "                    diffusion_loss = self.mse(pred_noise, noise)\n",
    "                else:\n",
    "                    diffusion_loss = torch.tensor(0., device=DEVICE)\n",
    "\n",
    "                # 残差分类CE（无梯度重构）\n",
    "                with torch.no_grad():\n",
    "                    if hasattr(self.model, 'reconstruct_residual_fast'):\n",
    "                        res = self.model.reconstruct_residual_fast(imgs, ys, t_start=200, steps=8)\n",
    "                    else:\n",
    "                        res = MultiScaleResidualExtractor(self.model.unet, TIMESTEPS_SAFE).extract_one_timestep(\n",
    "                            imgs, ys, t_value=200, steps=8)\n",
    "                if hasattr(self.model, 'fusion_classifier'):\n",
    "                    logits = self.model.fusion_classifier(res.unsqueeze(1).to(next(self.model.fusion_classifier.parameters()).device))\n",
    "                else:\n",
    "                    logits = self.model.classifier(res)\n",
    "                ce = self.ce(logits, ys)\n",
    "                loss = diffusion_loss + 0.5 * ce\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(self.optim)\n",
    "            self.scaler.update()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == ys).sum().item()\n",
    "                total += ys.size(0)\n",
    "                loss_sum += loss.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, loader):\n",
    "        \"\"\"验证：单视图，标准流程\"\"\"\n",
    "        self.model.eval()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            res_stack, logits = self.model(imgs, labels=ys, mode='eval')\n",
    "            ce = self.ce(logits, ys)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred==ys).sum().item()\n",
    "            total += ys.size(0)\n",
    "            loss_sum += ce.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "\n",
    "# ==================== Innovation1专用组件 ====================\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"对比学习投影头\"\"\"\n",
    "    def __init__(self, in_dim, out_dim=128, hidden=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, h):\n",
    "        return F.normalize(self.net(h), dim=-1)\n",
    "\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    \"\"\"监督对比损失\"\"\"\n",
    "    def __init__(self, temperature=0.2):\n",
    "        super().__init__()\n",
    "        self.tau = temperature\n",
    "    def forward(self, z, y):\n",
    "        sim = z @ z.t() / self.tau\n",
    "        sim = sim - torch.eye(sim.size(0), device=sim.device) * 1e9\n",
    "        y1, y2 = y.unsqueeze(1), y.unsqueeze(0)\n",
    "        pos_mask = (y1 == y2).float() - torch.eye(y.size(0), device=y.device)\n",
    "        log_prob = sim - torch.logsumexp(sim, dim=1, keepdim=True)\n",
    "        pos_log = (pos_mask * log_prob).sum(1) / (pos_mask.sum(1) + 1e-9)\n",
    "        return -pos_log.mean()\n",
    "\n",
    "class ProtoBank(nn.Module):\n",
    "    \"\"\"原型库：维护类中心 μ_c（EMA）\"\"\"\n",
    "    def __init__(self, num_classes, feat_dim, momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.m = momentum\n",
    "        self.register_buffer(\"mu\", torch.zeros(num_classes, feat_dim))\n",
    "        self.register_buffer(\"cnt\", torch.zeros(num_classes))\n",
    "    @torch.no_grad()\n",
    "    def update(self, h, y):\n",
    "        for c in y.unique():\n",
    "            c = int(c.item())\n",
    "            msk = (y == c)\n",
    "            if msk.sum() == 0: continue\n",
    "            mean_c = h[msk].mean(0)\n",
    "            self.mu[c] = self.m * self.mu[c] + (1 - self.m) * mean_c\n",
    "            self.cnt[c] += msk.sum()\n",
    "    def residual(self, h, y):\n",
    "        return h - self.mu[y]\n",
    "\n",
    "class _FeatHook:\n",
    "    \"\"\"特征钩子：抓取分类器最后线性层输入\"\"\"\n",
    "    def __init__(self, module: nn.Module):\n",
    "        self.buffer = None\n",
    "        self.h = module.register_forward_hook(self._hook)\n",
    "    def _hook(self, mod, inp, out):\n",
    "        self.buffer = inp[0].detach()\n",
    "    def close(self):\n",
    "        self.h.remove()\n",
    "\n",
    "def _find_last_linear(m: nn.Module):\n",
    "    \"\"\"找到模块中最后一个Linear层\"\"\"\n",
    "    last_lin = None\n",
    "    for mod in m.modules():\n",
    "        if isinstance(mod, nn.Linear):\n",
    "            last_lin = mod\n",
    "    return last_lin\n",
    "\n",
    "\n",
    "# ==================== Innovation1专用Trainer ====================\n",
    "# 功能：支持类条件FiLM + 掩膜训练 + 三重约束（对比/原型/一致性）\n",
    "# 适用于：Innovation1FaultDetector\n",
    "class Innovation1Trainer:\n",
    "    \"\"\"Innovation1专用训练器：FiLM + 掩膜 + 三重约束\"\"\"\n",
    "    def __init__(self, model: nn.Module, lr=2e-4, weight_decay=5e-4,\n",
    "                 proj_dim=128, contrast_tau=0.2,\n",
    "                 lambda_contrast=0.2, lambda_proto=0.1, lambda_mv=0.1,\n",
    "                 mv_on_logits=True, tta_times=2):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.scaler = GradScaler(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available())\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        self.mv_on_logits = mv_on_logits\n",
    "        self.lambda_contrast = lambda_contrast\n",
    "        self.lambda_proto = lambda_proto\n",
    "        self.lambda_mv = lambda_mv\n",
    "        self.tta_times = tta_times\n",
    "\n",
    "        # 三重约束组件初始化\n",
    "        cls_mod = getattr(self.model, 'fusion_classifier', None) or getattr(self.model, 'classifier', None)\n",
    "        assert cls_mod is not None, \"未找到分类模块\"\n",
    "        last_lin = _find_last_linear(cls_mod)\n",
    "        assert last_lin is not None, \"分类器内未找到Linear层\"\n",
    "\n",
    "        self._hook = _FeatHook(last_lin)\n",
    "        feat_dim = last_lin.in_features\n",
    "        num_classes = last_lin.out_features\n",
    "\n",
    "        self.proj = ProjectionHead(feat_dim, proj_dim, max(256, proj_dim*4)).to(DEVICE)\n",
    "        self.supcon = SupervisedContrastiveLoss(contrast_tau).to(DEVICE)\n",
    "        self.protos = ProtoBank(num_classes, feat_dim, momentum=0.9).to(DEVICE)\n",
    "\n",
    "    def _forward_classify_logits_and_feat(self, residual_tensor):\n",
    "        \"\"\"前向分类，返回 (logits, h)\"\"\"\n",
    "        if hasattr(self.model, 'fusion_classifier'):\n",
    "            logits = self.model.fusion_classifier(residual_tensor.unsqueeze(1).to(next(self.model.fusion_classifier.parameters()).device))\n",
    "        else:\n",
    "            logits = self.model.classifier(residual_tensor)\n",
    "        h = self._hook.buffer if (self._hook and self._hook.buffer is not None) else None\n",
    "        return logits, h\n",
    "\n",
    "    def train_epoch(self, loader):\n",
    "        \"\"\"训练：双视图(x1=常规, x2=掩膜) + 三重约束\"\"\"\n",
    "        self.model.train()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "\n",
    "        for x1, x2, ys in loader:  # 双视图loader\n",
    "            x1 = x1.to(DEVICE); x2 = x2.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            self.optim.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(AMP_DEVICE, enabled=USE_FP16 and torch.cuda.is_available()):\n",
    "                # 扩散MSE（类条件传递）\n",
    "                out = self.model(x1, labels=ys, mode='train')\n",
    "                if isinstance(out, tuple):\n",
    "                    pred_noise, noise, t, _ = out\n",
    "                    diffusion_loss = self.mse(pred_noise, noise)\n",
    "                else:\n",
    "                    diffusion_loss = torch.tensor(0., device=DEVICE)\n",
    "\n",
    "                # 残差提取（双视图，类条件传递）\n",
    "                with torch.no_grad():\n",
    "                    if hasattr(self.model, 'reconstruct_residual_fast'):\n",
    "                        res1 = self.model.reconstruct_residual_fast(x1, ys, t_start=200, steps=8)\n",
    "                        res2 = self.model.reconstruct_residual_fast(x2, ys, t_start=200, steps=8)\n",
    "                    else:\n",
    "                        extractor = MultiScaleResidualExtractor(self.model.diffusion_model, TIMESTEPS_SAFE)\n",
    "                        res1 = extractor.extract_one_timestep(x1, ys, t_value=200, steps=8)\n",
    "                        res2 = extractor.extract_one_timestep(x2, ys, t_value=200, steps=8)\n",
    "\n",
    "                # 分类 + 特征提取\n",
    "                logits1, h1 = self._forward_classify_logits_and_feat(res1)\n",
    "                logits2, h2 = self._forward_classify_logits_and_feat(res2)\n",
    "                ce = self.ce(logits1, ys)\n",
    "\n",
    "                # 三重约束：对比 + 原型 + 一致性\n",
    "                z1 = self.proj(h1); z2 = self.proj(h2)\n",
    "                zcat = torch.cat([z1, z2], 0)\n",
    "                ycat = torch.cat([ys, ys], 0)\n",
    "                loss_con = self.supcon(zcat, ycat)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    self.protos.update(h1.detach(), ys)\n",
    "                    self.protos.update(h2.detach(), ys)\n",
    "                r1 = self.protos.residual(h1, ys)\n",
    "                r2 = self.protos.residual(h2, ys)\n",
    "                loss_proto = 0.5 * (r1.norm(dim=1).mean() + r2.norm(dim=1).mean())\n",
    "\n",
    "                if self.mv_on_logits:\n",
    "                    p1 = F.log_softmax(logits1, dim=1)\n",
    "                    p2 = F.softmax(logits2, dim=1)\n",
    "                    loss_mv = 0.5 * (\n",
    "                        F.kl_div(p1, p2, reduction=\"batchmean\") +\n",
    "                        F.kl_div(F.log_softmax(logits2, dim=1), F.softmax(logits1, dim=1), reduction=\"batchmean\")\n",
    "                    )\n",
    "                else:\n",
    "                    loss_mv = F.mse_loss(r1, r2)\n",
    "\n",
    "                loss = diffusion_loss + 0.5 * ce + \\\n",
    "                       self.lambda_contrast * loss_con + \\\n",
    "                       self.lambda_proto * loss_proto + \\\n",
    "                       self.lambda_mv * loss_mv\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.scaler.step(self.optim)\n",
    "            self.scaler.update()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = logits1.argmax(1)\n",
    "                correct += (pred == ys).sum().item()\n",
    "                total += ys.size(0)\n",
    "                loss_sum += loss.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, loader):\n",
    "        \"\"\"验证：单视图 + TTA（水平翻转）\"\"\"\n",
    "        self.model.eval()\n",
    "        total, correct, loss_sum = 0, 0, 0.0\n",
    "        for imgs, ys in loader:\n",
    "            imgs = imgs.to(DEVICE); ys = ys.to(DEVICE)\n",
    "            res_stack, logits = self.model(imgs, labels=ys, mode='eval')\n",
    "            if self.tta_times > 1:\n",
    "                logits_flip = self.model(torch.flip(imgs, dims=[-1]), labels=ys, mode='eval')[1]\n",
    "                logits = 0.5 * (logits + logits_flip)\n",
    "            ce = self.ce(logits, ys)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred == ys).sum().item()\n",
    "            total += ys.size(0)\n",
    "            loss_sum += ce.item() * ys.size(0)\n",
    "        return loss_sum/total, correct/total\n",
    "\n",
    "    def close(self):\n",
    "        if self._hook:\n",
    "            self._hook.close()\n",
    "\n",
    "print('[Info] 已创建双Trainer系统：BaselineTrainer（无约束） + Innovation1Trainer（FiLM+掩膜+三重约束）')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cffbeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineFaultDetector params(M): 25.453033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_type = 'baseline'  # 可选：'baseline' | 'innov1' | 'innov2'\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    model = BaselineFaultDetector(num_classes=len(CLASS_NAMES))\n",
    "elif model_type == 'innov1':\n",
    "    model = Innovation1FaultDetector(num_classes=len(CLASS_NAMES))\n",
    "else:\n",
    "    model = Innovation2FaultDetector(num_classes=len(CLASS_NAMES),\n",
    "                                     use_transformer=False,\n",
    "                                     timesteps=[200],\n",
    "                                     lightweight=True)\n",
    "\n",
    "print(model.__class__.__name__, 'params(M):', sum(p.numel() for p in model.parameters())/1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac9d8e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] === Baseline训练开始 ===\n",
      "[Info] 模型：BaselineFaultDetector\n",
      "[Info] 训练器：BaselineTrainer（无FiLM、无掩膜、无三重约束）\n",
      "[Info] 数据：单视图（无掩膜）\n",
      "Epoch 01 | train loss 20.4128 acc 0.2734 | val loss 1.9404 acc 0.3336\n",
      "[SAVE] best acc 0.3336 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 02 | train loss 1.0031 acc 0.4007 | val loss 1.7939 acc 0.4325\n",
      "[SAVE] best acc 0.4325 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 03 | train loss 0.8375 acc 0.4895 | val loss 1.4941 acc 0.4985\n",
      "[SAVE] best acc 0.4985 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 04 | train loss 0.7193 acc 0.5437 | val loss 1.5195 acc 0.5376\n",
      "[SAVE] best acc 0.5376 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 05 | train loss 0.6642 acc 0.5867 | val loss 2.3013 acc 0.5353\n",
      "Epoch 06 | train loss 0.6457 acc 0.5913 | val loss 1.3629 acc 0.5698\n",
      "[SAVE] best acc 0.5698 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 07 | train loss 0.5787 acc 0.6371 | val loss 1.8322 acc 0.5445\n",
      "Epoch 08 | train loss 0.5777 acc 0.6346 | val loss 1.2812 acc 0.5752\n",
      "[SAVE] best acc 0.5752 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 09 | train loss 0.5640 acc 0.6490 | val loss 2.4791 acc 0.5667\n",
      "Epoch 10 | train loss 0.5068 acc 0.6798 | val loss 1.8555 acc 0.5928\n",
      "[SAVE] best acc 0.5928 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 11 | train loss 0.5067 acc 0.6860 | val loss 1.5230 acc 0.5913\n",
      "Epoch 12 | train loss 0.5073 acc 0.6833 | val loss 1.6238 acc 0.5989\n",
      "[SAVE] best acc 0.5989 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 13 | train loss 0.4711 acc 0.7036 | val loss 1.2175 acc 0.6465\n",
      "[SAVE] best acc 0.6465 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 14 | train loss 0.4583 acc 0.7155 | val loss 1.1920 acc 0.6319\n",
      "Epoch 15 | train loss 0.4642 acc 0.7038 | val loss 1.1770 acc 0.6373\n",
      "Epoch 16 | train loss 0.4314 acc 0.7295 | val loss 1.3133 acc 0.6342\n",
      "Epoch 17 | train loss 0.4219 acc 0.7402 | val loss 1.1034 acc 0.6587\n",
      "[SAVE] best acc 0.6587 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 18 | train loss 0.4264 acc 0.7364 | val loss 1.0876 acc 0.6718\n",
      "[SAVE] best acc 0.6718 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 19 | train loss 0.4183 acc 0.7414 | val loss 1.0915 acc 0.6771\n",
      "[SAVE] best acc 0.6771 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 20 | train loss 0.3838 acc 0.7644 | val loss 1.1884 acc 0.6618\n",
      "Epoch 21 | train loss 0.3896 acc 0.7584 | val loss 1.2230 acc 0.6587\n",
      "Epoch 22 | train loss 0.3714 acc 0.7699 | val loss 1.1092 acc 0.6733\n",
      "Epoch 23 | train loss 0.3654 acc 0.7751 | val loss 1.3103 acc 0.6603\n",
      "Epoch 24 | train loss 0.3544 acc 0.7914 | val loss 1.1045 acc 0.6833\n",
      "[SAVE] best acc 0.6833 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 25 | train loss 0.3479 acc 0.7818 | val loss 1.0960 acc 0.7002\n",
      "[SAVE] best acc 0.7002 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 26 | train loss 0.3323 acc 0.7974 | val loss 1.1376 acc 0.6894\n",
      "Epoch 27 | train loss 0.3416 acc 0.7918 | val loss 1.1720 acc 0.6603\n",
      "Epoch 28 | train loss 0.3312 acc 0.7975 | val loss 1.1183 acc 0.7032\n",
      "[SAVE] best acc 0.7032 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 29 | train loss 0.3014 acc 0.8190 | val loss 1.0587 acc 0.7147\n",
      "[SAVE] best acc 0.7147 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 30 | train loss 0.3081 acc 0.8225 | val loss 1.2019 acc 0.6595\n",
      "Epoch 31 | train loss 0.3156 acc 0.8148 | val loss 1.0503 acc 0.6940\n",
      "Epoch 32 | train loss 0.2766 acc 0.8347 | val loss 1.0921 acc 0.7055\n",
      "Epoch 33 | train loss 0.2698 acc 0.8351 | val loss 1.1828 acc 0.7002\n",
      "Epoch 34 | train loss 0.2868 acc 0.8276 | val loss 1.0675 acc 0.7186\n",
      "[SAVE] best acc 0.7186 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 35 | train loss 0.2647 acc 0.8430 | val loss 1.1242 acc 0.7009\n",
      "Epoch 36 | train loss 0.2624 acc 0.8487 | val loss 1.0563 acc 0.7163\n",
      "Epoch 37 | train loss 0.2564 acc 0.8539 | val loss 1.1223 acc 0.7109\n",
      "Epoch 38 | train loss 0.2422 acc 0.8618 | val loss 1.1227 acc 0.7216\n",
      "[SAVE] best acc 0.7216 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 39 | train loss 0.2170 acc 0.8714 | val loss 1.1186 acc 0.7324\n",
      "[SAVE] best acc 0.7324 -> ./baseline_substation_part2_best.pt\n",
      "Epoch 40 | train loss 0.2379 acc 0.8683 | val loss 1.1462 acc 0.7247\n",
      "Epoch 41 | train loss 0.2167 acc 0.8685 | val loss 1.1517 acc 0.7308\n",
      "Epoch 42 | train loss 0.2296 acc 0.8715 | val loss 1.1789 acc 0.7232\n",
      "Epoch 43 | train loss 0.2341 acc 0.8637 | val loss 1.1401 acc 0.7239\n",
      "Epoch 44 | train loss 0.2202 acc 0.8790 | val loss 1.2223 acc 0.7101\n",
      "Epoch 45 | train loss 0.2188 acc 0.8746 | val loss 1.2567 acc 0.7132\n",
      "Epoch 46 | train loss 0.2114 acc 0.8842 | val loss 1.2927 acc 0.7201\n",
      "Epoch 47 | train loss 0.2127 acc 0.8813 | val loss 1.2553 acc 0.7301\n",
      "Epoch 48 | train loss 0.2164 acc 0.8794 | val loss 1.3223 acc 0.7270\n",
      "Epoch 49 | train loss 0.1984 acc 0.8944 | val loss 1.3473 acc 0.7132\n",
      "Epoch 50 | train loss 0.2130 acc 0.8786 | val loss 1.3277 acc 0.7209\n"
     ]
    }
   ],
   "source": [
    "# ==================== Baseline 训练（纯净版）====================\n",
    "# 特点：无FiLM、无掩膜、无三重约束，仅扩散MSE + 残差分类CE\n",
    "\n",
    "epochs = 50\n",
    "# 使用BaselineTrainer（无额外约束）\n",
    "trainer_baseline = BaselineTrainer(\n",
    "    model,\n",
    "    lr=2e-4,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "best_acc, best_state = 0.0, None\n",
    "save_path = './baseline_substation_part2_best.pt'\n",
    "\n",
    "print('[Info] === Baseline训练开始 ===')\n",
    "print(f'[Info] 模型：{model.__class__.__name__}')\n",
    "print(f'[Info] 训练器：BaselineTrainer（无FiLM、无掩膜、无三重约束）')\n",
    "print(f'[Info] 数据：单视图（无掩膜）')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss, tr_acc = trainer_baseline.train_epoch(train_loader_baseline)  # 使用baseline专用loader\n",
    "    va_loss, va_acc = trainer_baseline.validate(val_loader_baseline)       # 使用baseline专用loader\n",
    "    print(f'Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}')\n",
    "\n",
    "    if va_acc > best_acc:\n",
    "        best_acc = va_acc\n",
    "        best_state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': best_acc,\n",
    "            'classes': list(CLASS_NAMES),\n",
    "            'img_size': img_size,\n",
    "            'model_type': 'baseline'\n",
    "        }\n",
    "        torch.save(best_state, save_path)\n",
    "        print(f'[SAVE] best acc {best_acc:.4f} -> {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce00368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1028/711229185.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load('./baseline_substation_part2_best.pt', map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint with acc: 0.7323619631901841\n",
      "Final Val -> loss: 1.1608 acc: 0.7239\n"
     ]
    }
   ],
   "source": [
    "# ==================== Baseline 验证 ====================\n",
    "\n",
    "if os.path.exists('./baseline_substation_part2_best.pt'):\n",
    "    ckpt = torch.load('./baseline_substation_part2_best.pt', map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    print('Loaded best checkpoint with acc:', ckpt.get('acc', None))\n",
    "else:\n",
    "    print('No checkpoint found, using current model.')\n",
    "\n",
    "# 重用训练时的trainer_baseline，避免重新初始化\n",
    "va_loss, va_acc = trainer_baseline.validate(val_loader_baseline)\n",
    "print('Final Val -> loss:', round(va_loss,4), 'acc:', round(va_acc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df6afe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Innovation1FaultDetector params(M): 25.584446\n"
     ]
    }
   ],
   "source": [
    "# innov1 模型\n",
    "\n",
    "model_type = 'innov1'  # 可选：'baseline' | 'innov1' | 'innov2'\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    model = BaselineFaultDetector(num_classes=len(CLASS_NAMES))\n",
    "elif model_type == 'innov1':\n",
    "    model = Innovation1FaultDetector(num_classes=len(CLASS_NAMES))\n",
    "else:\n",
    "    model = Innovation2FaultDetector(num_classes=len(CLASS_NAMES),\n",
    "                                     use_transformer=False,\n",
    "                                     timesteps=[200],\n",
    "                                     lightweight=True)\n",
    "\n",
    "print(model.__class__.__name__, 'params(M):', sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d15857e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] === Innovation1训练开始 ===\n",
      "[Info] 模型：Innovation1FaultDetector\n",
      "[Info] 训练器：Innovation1Trainer（类条件FiLM + 掩膜训练 + 三重约束）\n",
      "[Info] 数据：双视图（含掩膜）\n",
      "Epoch 01 | train loss 50.1442 acc 0.2818 | val loss 1.6864 acc 0.4179\n",
      "[SAVE] best acc 0.4179 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 02 | train loss 2.7704 acc 0.4473 | val loss 1.4404 acc 0.5084\n",
      "[SAVE] best acc 0.5084 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 03 | train loss 2.6908 acc 0.5213 | val loss 1.5010 acc 0.5023\n",
      "Epoch 04 | train loss 2.6564 acc 0.5796 | val loss 1.3207 acc 0.5406\n",
      "[SAVE] best acc 0.5406 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 05 | train loss 2.6230 acc 0.6008 | val loss 1.2437 acc 0.5652\n",
      "[SAVE] best acc 0.5652 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 06 | train loss 2.5835 acc 0.6114 | val loss 1.1490 acc 0.5989\n",
      "[SAVE] best acc 0.5989 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 07 | train loss 2.5626 acc 0.6587 | val loss 1.1025 acc 0.6135\n",
      "[SAVE] best acc 0.6135 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 08 | train loss 2.5699 acc 0.6658 | val loss 1.0998 acc 0.6227\n",
      "[SAVE] best acc 0.6227 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 09 | train loss 2.5322 acc 0.6823 | val loss 1.1762 acc 0.6112\n",
      "Epoch 10 | train loss 2.5478 acc 0.7002 | val loss 1.1141 acc 0.6304\n",
      "[SAVE] best acc 0.6304 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 11 | train loss 2.5152 acc 0.7069 | val loss 1.0239 acc 0.6488\n",
      "[SAVE] best acc 0.6488 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 12 | train loss 2.5087 acc 0.7178 | val loss 1.0867 acc 0.6235\n",
      "Epoch 13 | train loss 2.4702 acc 0.7345 | val loss 1.0135 acc 0.6687\n",
      "[SAVE] best acc 0.6687 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 14 | train loss 2.4763 acc 0.7465 | val loss 1.0568 acc 0.6534\n",
      "Epoch 15 | train loss 2.4719 acc 0.7414 | val loss 1.1052 acc 0.6365\n",
      "Epoch 16 | train loss 2.4472 acc 0.7696 | val loss 0.9928 acc 0.6718\n",
      "[SAVE] best acc 0.6718 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 17 | train loss 2.4549 acc 0.7828 | val loss 1.0023 acc 0.6810\n",
      "[SAVE] best acc 0.6810 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 18 | train loss 2.4439 acc 0.7895 | val loss 1.0472 acc 0.6664\n",
      "Epoch 19 | train loss 2.4157 acc 0.7715 | val loss 0.9875 acc 0.6963\n",
      "[SAVE] best acc 0.6963 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 20 | train loss 2.4062 acc 0.7928 | val loss 0.9210 acc 0.7040\n",
      "[SAVE] best acc 0.7040 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 21 | train loss 2.4047 acc 0.7964 | val loss 1.0073 acc 0.6733\n",
      "Epoch 22 | train loss 2.3660 acc 0.7929 | val loss 0.9113 acc 0.7048\n",
      "[SAVE] best acc 0.7048 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 23 | train loss 2.3618 acc 0.8112 | val loss 0.9752 acc 0.7009\n",
      "Epoch 24 | train loss 2.3658 acc 0.8096 | val loss 0.9782 acc 0.7071\n",
      "[SAVE] best acc 0.7071 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 25 | train loss 2.3576 acc 0.8117 | val loss 0.9076 acc 0.7278\n",
      "[SAVE] best acc 0.7278 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 26 | train loss 2.3581 acc 0.8292 | val loss 0.9330 acc 0.7063\n",
      "Epoch 27 | train loss 2.3526 acc 0.8305 | val loss 0.9915 acc 0.7048\n",
      "Epoch 28 | train loss 2.3373 acc 0.8194 | val loss 0.9473 acc 0.7324\n",
      "[SAVE] best acc 0.7324 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 29 | train loss 2.3119 acc 0.8439 | val loss 1.0205 acc 0.7124\n",
      "Epoch 30 | train loss 2.3049 acc 0.8443 | val loss 0.9171 acc 0.7393\n",
      "[SAVE] best acc 0.7393 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 31 | train loss 2.3271 acc 0.8292 | val loss 1.0088 acc 0.7109\n",
      "Epoch 32 | train loss 2.3160 acc 0.8476 | val loss 0.9489 acc 0.7178\n",
      "Epoch 33 | train loss 2.2851 acc 0.8566 | val loss 1.0132 acc 0.7132\n",
      "Epoch 34 | train loss 2.2795 acc 0.8514 | val loss 0.9136 acc 0.7347\n",
      "Epoch 35 | train loss 2.2732 acc 0.8702 | val loss 0.9740 acc 0.7178\n",
      "Epoch 36 | train loss 2.2573 acc 0.8712 | val loss 1.0059 acc 0.7101\n",
      "Epoch 37 | train loss 2.2448 acc 0.8654 | val loss 1.1444 acc 0.6902\n",
      "Epoch 38 | train loss 2.2411 acc 0.8813 | val loss 0.9640 acc 0.7324\n",
      "Epoch 39 | train loss 2.2532 acc 0.8836 | val loss 0.9225 acc 0.7431\n",
      "[SAVE] best acc 0.7431 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 40 | train loss 2.2373 acc 0.8796 | val loss 0.9262 acc 0.7354\n",
      "Epoch 41 | train loss 2.2327 acc 0.8957 | val loss 0.9567 acc 0.7362\n",
      "Epoch 42 | train loss 2.2324 acc 0.8963 | val loss 0.9416 acc 0.7469\n",
      "[SAVE] best acc 0.7469 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 43 | train loss 2.2181 acc 0.8942 | val loss 0.9170 acc 0.7531\n",
      "[SAVE] best acc 0.7531 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 44 | train loss 2.2280 acc 0.9070 | val loss 1.0796 acc 0.7155\n",
      "Epoch 45 | train loss 2.2132 acc 0.8921 | val loss 1.0176 acc 0.7301\n",
      "Epoch 46 | train loss 2.2084 acc 0.8955 | val loss 0.9285 acc 0.7446\n",
      "Epoch 47 | train loss 2.1938 acc 0.8946 | val loss 0.8845 acc 0.7584\n",
      "[SAVE] best acc 0.7584 -> ./innov1_substation_part2_best.pt\n",
      "Epoch 48 | train loss 2.1856 acc 0.8959 | val loss 0.9789 acc 0.7178\n",
      "Epoch 49 | train loss 2.1656 acc 0.8944 | val loss 1.0346 acc 0.7270\n",
      "Epoch 50 | train loss 2.1664 acc 0.8748 | val loss 1.0136 acc 0.7339\n"
     ]
    }
   ],
   "source": [
    "# ==================== Innovation1 训练（FiLM + 掩膜 + 三重约束）====================\n",
    "\n",
    "epochs = 50\n",
    "# 使用Innovation1Trainer（FiLM + 掩膜 + 三重约束）\n",
    "trainer_innov1 = Innovation1Trainer(\n",
    "    model,\n",
    "    lr=2e-4,\n",
    "    weight_decay=5e-4,\n",
    "    proj_dim=128,\n",
    "    contrast_tau=0.2,\n",
    "    lambda_contrast=0.2,\n",
    "    lambda_proto=0.1,\n",
    "    lambda_mv=0.1,\n",
    "    mv_on_logits=True,\n",
    "    tta_times=2\n",
    ")\n",
    "\n",
    "best_acc, best_state = 0.0, None\n",
    "save_path = './innov1_substation_part2_best.pt'\n",
    "\n",
    "print('[Info] === Innovation1训练开始 ===')\n",
    "print(f'[Info] 模型：{model.__class__.__name__}')\n",
    "print(f'[Info] 训练器：Innovation1Trainer（类条件FiLM + 掩膜训练 + 三重约束）')\n",
    "print(f'[Info] 数据：双视图（含掩膜）')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss, tr_acc = trainer_innov1.train_epoch(train_loader_innov1)  # 使用innov1专用loader\n",
    "    va_loss, va_acc = trainer_innov1.validate(val_loader_innov1)       # 使用innov1专用loader\n",
    "    print(f'Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}')\n",
    "    \n",
    "    if va_acc > best_acc:\n",
    "        best_acc = va_acc\n",
    "        best_state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': best_acc,\n",
    "            'classes': list(CLASS_NAMES),\n",
    "            'img_size': img_size,\n",
    "            'model_type': 'innovation1'\n",
    "        }\n",
    "        torch.save(best_state, save_path)\n",
    "        print(f'[SAVE] best acc {best_acc:.4f} -> {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b23af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1028/769296093.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load('./innov1_substation_part2_best.pt', map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint with acc: 0.7584355828220859\n",
      "Final Val -> loss: 0.876 acc: 0.7523\n"
     ]
    }
   ],
   "source": [
    "# ==================== Innovation1 验证 ====================\n",
    "\n",
    "if os.path.exists('./innov1_substation_part2_best.pt'):\n",
    "    ckpt = torch.load('./innov1_substation_part2_best.pt', map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    print('Loaded best checkpoint with acc:', ckpt.get('acc', None))\n",
    "else:\n",
    "    print('No checkpoint found, using current model.')\n",
    "\n",
    "# 重用训练时的trainer_innov1，避免重新初始化\n",
    "va_loss, va_acc = trainer_innov1.validate(val_loader_innov1)\n",
    "print('Final Val -> loss:', round(va_loss,4), 'acc:', round(va_acc,4))\n",
    "\n",
    "# 关闭hook\n",
    "trainer_innov1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2925e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74453575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plant-py310-test)",
   "language": "python",
   "name": "plant-py310-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
